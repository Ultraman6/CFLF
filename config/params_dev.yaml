deep_learning_settings:
  dataset: "mnist"
  synthetic:
    mean: 1
    variance: 1
    dimension: 60
    num_class: 10
  model: "cnn"
  init_mode: "xaiver_uniform"
  batch_size: 10
  learning_rate: 0.01
  loss_function: "ce"
  optimizer: 'sgd'
  sgd:
    momentum: 0.9
    weight_decay: 0.0001
  adam:
    weight_decay: 0.0001
    beta_1: 0.9
    beta_2: 0.999
    epsilon: 1e-7
  scheduler: "none"
  common:
    lr_decay_step: 100
    lr_decay_rate: 0.1
  cosineAnnealing:
    lr_min: 0
  grad_norm: 0
  grad_clip: 0

federated_learning_settings:
  round: 10
  epoch: 10
  num_clients: 20
  valid_ratio: 0.1
  data_type: "homo"
  dirichlet:
    alpha: 0.3
  shards:
    class_per_client: 3
  custom_class:
    class_mapping: { "0": 1, "1": 1, "2": 2, "3": 2, "4": 3, "5": 3,
                     "6": 4, "7": 4, "8": 5, "9": 5, "10": 6, "11": 6,
                     "12": 7, "13": 7, "14": 8, "15": 8, "16": 9, "17": 9,
                     "18": 10, "19": 10
    }
  noise_feature:
    noise_mapping: { "0": [ 0.2, 0.2 ], "1": [ 0.2, 0.2 ], "2": [ 0.2, 0.2 ],
                     "3": [ 0.2, 0.2 ], "4": [ 0.2, 0.2 ]
    }
  noise_label:
    noise_mapping: { "0": [ 0.2, 0.2 ], "1": [ 0.2, 0.2 ], "2": [ 0.2, 0.2 ],
                     "3": [ 0.2, 0.2 ], "4": [ 0.2, 0.2 ]
    }
  num_type: "average"
  customized single:
    sample_per_client: 1000
  customized each:
    sample_mapping: { "0": 1000, "1": 1000, "2": 1000, "3": 1000, "4": 1000, "5": 1000,
                      "6": 1000, "7": 1000, "8": 1000, "9": 1000, "10": 1000, "11": 1000,
                      "12": 1000, "13": 1000, "14": 1000, "15": 1000, "16": 1000, "17": 1000,
                      "18": 1000, "19": 1000
    }

running_settings:
  dataset_root: "../../datasets"
  result_root: "../../result"
  show_distribution: false
  device: "gpu"
  gpu:
    gpu_mapping: [ 0 ]
  seed: 1
  seed_num: 1
  running_mode: "serial"
  thread:
    max_threads: 20
  process:
    max_processes: 10
  save_model: false
  standalone: false

algo_settings:
  common:
  fedetf:
    gamma: 0.8
    rho: 0.95
    eta: 0.9
    e: 4
    reward_mode: "mask"
    time_mode: "exp"
    fair: 3
    lamb: 0.5
    p_cali: 1.0